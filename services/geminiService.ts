
import { GoogleGenAI, Type, Modality } from "@google/genai";
import { AstraModel, AstraAgent, ImageGenConfig, SandboxConfig, Task } from "../types";

// Helper to create AI client with the latest API key from environment
export const createAiClient = () => {
  return new GoogleGenAI({ apiKey: process.env.API_KEY });
};

// Helper to decode base64 strings to Uint8Array
export function decodeBase64(base64: string): Uint8Array {
  const binaryString = atob(base64.includes(',') ? base64.split(',')[1] : base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// Helper to decode raw PCM audio data into an AudioBuffer
export async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number = 24000,
  numChannels: number = 1
): Promise<AudioBuffer> {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}

// --- MCP Tool Definitions ---
const githubSearchTool = {
  name: "searchGithubRepositories",
  description: "Search for public GitHub repositories. Useful for finding libraries, tools, reference code, or project examples. Returns repository details including stars, description, and URL.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      query: { type: Type.STRING, description: "Search keywords (e.g. 'react admin dashboard', 'machine learning python')" },
      language: { type: Type.STRING, description: "Programming language filter (optional)" }
    },
    required: ["query"]
  }
};

const terminalTool = {
  name: "executeTerminalCommand",
  description: "Execute a shell command in a simulated Linux terminal. Use this to run code, manage files, install packages, or perform system operations. Supported commands: ls, cd, pwd, cat, echo, mkdir, touch, rm, npm, git, node, python.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      command: { type: Type.STRING, description: "The shell command to execute" }
    },
    required: ["command"]
  }
};

const taskTool = {
  name: "manageTasks",
  description: "Manage the user's to-do list. You can add tasks, remove tasks, toggle completion status, or list current tasks.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      action: { type: Type.STRING, description: "Action to perform: 'add', 'remove', 'toggle', 'list'" },
      task: { type: Type.STRING, description: "The task description (required for 'add')" },
      id: { type: Type.STRING, description: "The task ID (required for 'remove' or 'toggle')" }
    },
    required: ["action"]
  }
};

// Mock File System State
let fileSystem: Record<string, string> = {
  '/home/project/package.json': '{\n  "name": "astra-project",\n  "version": "1.0.0"\n}',
  '/home/project/README.md': '# Project\n\nGenerated by Astra AI'
};
let currentDir = '/home/project';

async function executeGithubSearch(args: any) {
    try {
        const q = args.language ? `${args.query} language:${args.language}` : args.query;
        // Using GitHub Search API (rate limited for unauthenticated requests, but sufficient for demo)
        const res = await fetch(`https://api.github.com/search/repositories?q=${encodeURIComponent(q)}&sort=stars&order=desc&per_page=5`);
        if (!res.ok) throw new Error("GitHub API Error");
        const data = await res.json();
        return {
            results: data.items.map((item: any) => ({
                name: item.full_name,
                description: item.description,
                url: item.html_url,
                stars: item.stargazers_count,
                language: item.language
            }))
        };
    } catch (e: any) {
        return { error: "Failed to search GitHub", details: e.message };
    }
}

async function executeTerminalCommand(args: any) {
  const cmd = args.command.trim();
  let output = "";

  // Dispatch event for UI
  const dispatch = (out: string) => {
     if (typeof window !== 'undefined') {
        window.dispatchEvent(new CustomEvent('astra-terminal', {
           detail: { command: cmd, output: out }
        }));
     }
     return out;
  };

  try {
    const parts = cmd.split(' ');
    const base = parts[0];

    if (base === 'ls') {
       const files = Object.keys(fileSystem).filter(k => k.startsWith(currentDir)).map(k => k.replace(currentDir + '/', ''));
       output = files.length ? files.join('\n') : '(empty)';
    } else if (base === 'pwd') {
       output = currentDir;
    } else if (base === 'cd') {
       const target = parts[1] || '/home/project';
       // Simple mock path resolution
       if (target === '..') {
          const split = currentDir.split('/');
          split.pop();
          currentDir = split.join('/') || '/';
       } else {
          currentDir = target.startsWith('/') ? target : `${currentDir}/${target}`;
       }
       output = currentDir;
    } else if (base === 'echo') {
       output = parts.slice(1).join(' ').replace(/['"]/g, '');
    } else if (base === 'cat') {
       const file = parts[1];
       const path = file.startsWith('/') ? file : `${currentDir}/${file}`;
       output = fileSystem[path] || `cat: ${file}: No such file or directory`;
    } else if (base === 'mkdir') {
       output = ""; // logic handled by just assuming path exists for now in this simple mock
    } else if (base === 'touch' || base === 'rm') {
       const file = parts[1];
       const path = file.startsWith('/') ? file : `${currentDir}/${file}`;
       if (base === 'touch') fileSystem[path] = '';
       else delete fileSystem[path];
       output = "";
    } else if (base === 'npm' && parts[1] === 'install') {
       const pkg = parts[2] || 'dependencies';
       await new Promise(r => setTimeout(r, 1000));
       output = `added 1 package, and audited 2 packages in 1s\nfound 0 vulnerabilities`;
    } else if (base === 'git' && parts[1] === 'clone') {
       const repo = parts[2];
       await new Promise(r => setTimeout(r, 1500));
       output = `Cloning into '${repo.split('/').pop()?.replace('.git', '')}'...\nremote: Enumerating objects: 100, done.\nremote: Total 100 (delta 10), reused 100 (delta 10)\nReceiving objects: 100% (100/100), done.`;
    } else if (base === 'node' || base === 'python') {
       output = `[Mock execution of ${base}]\nScript executed successfully.\nOutput: Hello from ${base}!`;
    } else {
       output = `${base}: command not found`;
    }
    
    return { result: dispatch(output) };

  } catch (e: any) {
    return { error: dispatch(`Error executing command: ${e.message}`) };
  }
}

async function executeTaskOperation(args: any) {
    const { action, task, id } = args;
    
    // Dispatch event to UI to update state
    if (typeof window !== 'undefined') {
        window.dispatchEvent(new CustomEvent('astra-task-event', {
            detail: { action, task, id }
        }));
    }
    
    return { status: "success", action, message: "Task list update requested." };
}

export const geminiService = {
  // Stream chat responses from the model
  async *streamChat(
    prompt: string, 
    history: any[], 
    config: { 
      model: string, 
      agent: AstraAgent,
      thinking?: boolean, 
      isViewMode?: boolean,
      isCodeMode?: boolean,
      image?: { data: string, mimeType: string },
      pdfText?: string,
      memory?: string[],
      tasks?: Task[],
      sandboxConfig?: SandboxConfig
    }
  ) {
    const ai = createAiClient();
    
    let systemInstruction = "You are Astra AI, a highly capable multi-modal assistant.";
    
    // Add Memory Context
    if (config.memory && config.memory.length > 0) {
      systemInstruction += `\nPersonal context about the user:\n${config.memory.map(f => `- ${f}`).join('\n')}`;
    }

    // Add Tasks Context
    if (config.tasks && config.tasks.length > 0) {
      systemInstruction += `\nCurrent To-Do List:\n${config.tasks.map(t => `- [${t.completed ? 'x' : ' '}] (ID: ${t.id}) ${t.text}`).join('\n')}`;
    }

    // Agent Specific Instructions
    if (!config.sandboxConfig) {
      switch (config.agent) {
        case AstraAgent.RESEARCHER:
          systemInstruction += `\nMODE: RESEARCHER. Use Google Search grounding for every query. Provide citations, deep dives, and academic-style formatting. Focus on facts and up-to-date data.`;
          break;
        case AstraAgent.CREATIVE:
          systemInstruction += `\nMODE: CREATIVE. Be poetic, descriptive, and imaginative. When asked for images, provide detailed artistic prompts. Focus on aesthetics and storytelling.`;
          break;
        case AstraAgent.CODER:
          systemInstruction += `\nMODE: CODER. You have access to a simulated terminal and task manager. Use 'executeTerminalCommand' to run shell commands. Use 'manageTasks' to track coding requirements. Prioritize code generation. Use clean, documented, and efficient logic. Use markdown code blocks.`;
          break;
        case AstraAgent.ANALYST:
          systemInstruction += `\nMODE: ANALYST. Focus on data extraction, summarizing documents, and logical deduction. Be objective and structured. Use tables where helpful.`;
          break;
        case AstraAgent.ARCHITECT:
          systemInstruction += `\nMODE: ARCHITECT. Focus on high-level system design, software architecture patterns, scalability, and planning. Provide structured technical plans, folder structures, and step-by-step implementation strategies. Use the GitHub search tool to find reference architectures if needed.`;
          break;
        case AstraAgent.NODEJS_EXPERT:
          systemInstruction += `\nMODE: NODEJS_EXPERT. You are an expert on the nodejs/node-v0.x-archive repository. You can answer questions about the repository, its history, and its code.`;
          break;
        default:
          systemInstruction += `\nMODE: GENERAL. Be helpful, concise, and balanced in your responses. You can manage the user's to-do list using the 'manageTasks' tool.`;
      }
    } else {
       // Sandbox Override
       systemInstruction = config.sandboxConfig.systemInstruction || systemInstruction;
    }

    if (config.isCodeMode) {
      systemInstruction += `\nCRITICAL OVERRIDE: CODE GENERATION MODE ACTIVE. You are now an expert coding engine. Prioritize generating complete, correct, and efficient code snippets. Use markdown code blocks for all code. Explain your logic briefly and clearly. Focus on syntax correctness and best practices.`;
    }

    if (config.isViewMode) {
      systemInstruction += `\nCRITICAL: You are now in VIEW MODE. Be extremely concise. Use bullet points and summaries. Avoid conversational filler.`;
    }

    if (config.thinking) {
      systemInstruction += `\nCRITICAL THINKING MODE ENABLED: Before providing your final answer, you MUST perform a comprehensive critical analysis of the task. Break down the problem, consider edge cases, and plan your response. Output this thinking process within <thinking>...</thinking> tags at the very beginning of your response.`;
    }

    if (config.pdfText) {
      systemInstruction += `\nDOCUMENT CONTEXT:\n${config.pdfText}\nAnswer based primarily on this content.`;
    }

    // Prepare contents
    let contents: any[] = [];

    // Inject Few-Shot Examples for Sandbox (Training)
    if (config.sandboxConfig?.examples && config.sandboxConfig.examples.length > 0) {
       config.sandboxConfig.examples.forEach(ex => {
          if (ex.input && ex.output) {
             contents.push({ role: 'user', parts: [{ text: ex.input }] });
             contents.push({ role: 'model', parts: [{ text: ex.output }] });
          }
       });
    }

    // Append standard history
    const historyContents = history.map(h => ({
      role: h.role,
      parts: [{ text: h.text }]
    }));
    contents = [...contents, ...historyContents];
    
    // Append current prompt
    const currentParts: any[] = [{ text: prompt }];
    if (config.image) {
      currentParts.push({
        inlineData: {
          data: config.image.data.split(',')[1],
          mimeType: config.image.mimeType
        }
      });
    }

    contents.push({ role: 'user', parts: currentParts });

    const tools: any[] = [{ googleSearch: {} }, { functionDeclarations: [taskTool] }];

    // Enable MCP-style Tools for specific agents
    if (config.agent === AstraAgent.CODER || config.agent === AstraAgent.ARCHITECT || config.isCodeMode) {
      // Ensure we don't duplicate function declarations if adding to existing array
      // Actually @google/genai supports multiple tool objects, so we can just push another one or merge.
      // But let's merge into one functionDeclarations array to be safe.
      const existingFuncs = (tools[1] as any).functionDeclarations;
      existingFuncs.push(githubSearchTool);
      existingFuncs.push(terminalTool);
    }

    const targetModel = (config.thinking || config.isCodeMode || config.agent === AstraAgent.CODER || config.agent === AstraAgent.RESEARCHER || config.agent === AstraAgent.ARCHITECT) ? AstraModel.PRO : config.model;

    const generationConfig: any = { 
      tools,
      systemInstruction 
    };

    if (config.thinking) {
      generationConfig.thinkingConfig = { thinkingBudget: 32768 };
    }
    
    // Apply Sandbox Parameters
    if (config.sandboxConfig) {
      generationConfig.temperature = config.sandboxConfig.temperature;
      generationConfig.topK = config.sandboxConfig.topK;
      generationConfig.topP = config.sandboxConfig.topP;
    }

    try {
      // First turn
      let stream = await ai.models.generateContentStream({
        model: targetModel,
        contents,
        config: generationConfig
      });

      let capturedFunctionCall: any = null;

      for await (const chunk of stream) {
        // If we have text, yield it
        if (chunk.text) {
          yield chunk;
        }
        // Check for function call in the response
        const fc = (chunk as any).functionCalls?.[0];
        if (fc) {
          capturedFunctionCall = fc;
        }
      }

      // Handle Tool Execution (Multi-turn)
      if (capturedFunctionCall) {
        let toolResult = {};
        
        if (capturedFunctionCall.name === 'searchGithubRepositories') {
           toolResult = await executeGithubSearch(capturedFunctionCall.args);
        } else if (capturedFunctionCall.name === 'executeTerminalCommand') {
           toolResult = await executeTerminalCommand(capturedFunctionCall.args);
        } else if (capturedFunctionCall.name === 'manageTasks') {
           toolResult = await executeTaskOperation(capturedFunctionCall.args);
        }

        // Construct new history for the model
        const newContents = [
          ...contents,
          { role: 'model', parts: [{ functionCall: capturedFunctionCall }] },
          { role: 'function', parts: [{ functionResponse: { name: capturedFunctionCall.name, response: toolResult } }] }
        ];

        // Call model again with tool results
        const finalStream = await ai.models.generateContentStream({
          model: targetModel,
          contents: newContents,
          config: generationConfig
        });

        for await (const chunk of finalStream) {
           if (chunk.text) yield chunk;
        }
      }

    } catch (error: any) {
      console.error("Stream Error:", error);
      let userFriendlyMessage = "I encountered an error processing your request.";
      if (error.message?.includes("Safety")) userFriendlyMessage = "The request was flagged by safety filters.";
      if (error.message?.includes("quota")) userFriendlyMessage = "API quota exceeded. Please try again later.";
      
      throw new Error(`${userFriendlyMessage} (Details: ${error.message})`);
    }
  },

  // Generate an image based on the prompt
  async generateImage(prompt: string, config: ImageGenConfig) {
    const ai = createAiClient();
    const model = config.quality === 'high' ? AstraModel.IMAGE_PRO : AstraModel.IMAGE_FLASH;
    const stylePrompt = config.style && config.style !== 'None' ? `, ${config.style} style` : '';
    const finalPrompt = `${prompt}${stylePrompt}`;

    try {
      const response = await ai.models.generateContent({
        model,
        contents: {
          parts: [{ text: finalPrompt }]
        },
        config: {
          imageConfig: {
            aspectRatio: config.aspectRatio,
            ...(config.quality === 'high' ? { imageSize: "1K" } : {})
          }
        }
      });

      for (const part of response.candidates?.[0]?.content?.parts || []) {
        if (part.inlineData) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
      return null;
    } catch (error: any) {
      console.error("Image Gen Error:", error);
      throw new Error(`Image generation failed: ${error.message}`);
    }
  },

  // Extract key facts about the user from the conversation history
  async updateMemory(history: any[]) {
    const ai = createAiClient();
    const recentConvo = history.slice(-4).map(h => `${h.role}: ${h.text}`).join('\n');
    const prompt = `Based on the following conversation, extract any new key facts about the user (name, preferences, interests, location, etc.) as a JSON array of strings. If no new facts, return []. \n\nCONVERSATION:\n${recentConvo}`;

    try {
      const response = await ai.models.generateContent({
        model: AstraModel.FLASH,
        contents: prompt,
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: Type.ARRAY,
            items: { type: Type.STRING }
          }
        }
      });
      return JSON.parse(response.text || "[]");
    } catch (error) {
      console.error("Memory Extraction Error:", error);
      return [];
    }
  },

  // Speak the provided text using Gemini's text-to-speech capabilities
  async speakText(text: string) {
    const ai = createAiClient();
    try {
      const response = await ai.models.generateContent({
        model: AstraModel.TTS,
        contents: [{ parts: [{ text }] }],
        config: {
          responseModalities: [Modality.AUDIO],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: { voiceName: 'Kore' },
            },
          },
        },
      });

      const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
      if (audioData) {
        const audioCtx = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
        const decodedBuffer = await decodeAudioData(
          decodeBase64(audioData),
          audioCtx,
          24000,
          1
        );
        const source = audioCtx.createBufferSource();
        source.buffer = decodedBuffer;
        source.connect(audioCtx.destination);
        source.start();
      }
    } catch (error) {
      console.error("TTS Error:", error);
    }
  }
};
